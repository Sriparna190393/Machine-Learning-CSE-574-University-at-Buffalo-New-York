{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,Input,Reshape,UpSampling2D\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from keras.callbacks import History\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.models import Model,Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Read Fashion MNIST dataset using Keras\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train, Y_train), (X_test,Y_test) = fashion_mnist.load_data() \n",
    "\n",
    "#normalise the dataset\n",
    "X_train = (X_train / 255.0)\n",
    "X_test = (X_test / 255.0)\n",
    "\n",
    "# Scales the training and test data to range between 0 and 1.\n",
    "X_train = np.float32(X_train)\n",
    "X_test = np.float32(X_test)\n",
    "\n",
    "#rescale the training and testing data with the maximum pixel value of the training and testing data\n",
    "X_train = X_train / np.max(X_train)\n",
    "X_test = X_test / np.max(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-means clustering - Task 1\n",
    "# Read Fashion MNIST dataset using Keras\n",
    "(X_train, Y_train), (X_test,Y_test) = fashion_mnist.load_data()\n",
    "clusters = len(np.unique(Y_train))\n",
    "\n",
    "nsamples_train, nx_train, ny_train = X_train.shape\n",
    "X_train = X_train.reshape((nsamples_train, nx_train * ny_train))\n",
    "nsamples_test, nx_test, ny_test = X_test.shape\n",
    "X_test = X_test.reshape((nsamples_test, nx_test * ny_test))\n",
    "\n",
    "#normalising the dataset\n",
    "X_train = (X_train / 255.0)\n",
    "X_test = (X_test / 255.0)\n",
    "\n",
    "for n in range(1,8):\n",
    "  #Run in parallel\n",
    "  kmeans = KMeans(n_clusters=n, random_state=42, n_init=20, n_jobs=4, max_iter=600)\n",
    "  kmeans.fit(X_train)\n",
    "  sse = kmeans.inertia_ \n",
    "  print('SSE for #cluster = ', n, 'is',sse)\n",
    "\n",
    "#Validating the model (Getting cluster labels)\n",
    "labels = kmeans.fit_predict(X_test)\n",
    "\n",
    "# Centroid values\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Observe and compare clustering result with actual label using confusion matrix\n",
    "y_test = copy.deepcopy(Y_test)\n",
    "cm = confusion_matrix(Y_test, labels)\n",
    "\n",
    "#visualize data\n",
    "plt.figure(figsize=(5, 5))\n",
    "ax = sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.title(\"Confusion matrix for simple K-means\", fontsize=25)\n",
    "plt.ylabel('True label', fontsize=20)\n",
    "plt.xlabel('Clustering label', fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "test_score = normalized_mutual_info_score(y_test,labels)\n",
    "print('TESTING ACCURACY : '+str(test_score))\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"----------------------------------------------------\")\n",
    "print(classification_report(Y_test,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building an Auto-encoder - Task 2\n",
    "#reshape\n",
    "X_train = X_train.reshape((len(X_train), 28, 28, 1))\n",
    "X_test = X_test.reshape((len(X_test), 28, 28, 1))\n",
    "\n",
    "#input dimension = 784\n",
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 32\n",
    "\n",
    "compression_factor = float(input_dim) / encoding_dim\n",
    "print(\"Compression factor: %s\" % compression_factor)\n",
    "\n",
    "autoencoder = Sequential()\n",
    "# Encoder Layers\n",
    "autoencoder.add(Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=X_train.shape[1:]))\n",
    "autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
    "autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(MaxPooling2D((2, 2), padding='same'))\n",
    "autoencoder.add(Conv2D(8, (3, 3), strides=(2,2), activation='relu', padding='same'))\n",
    "\n",
    "# Flatten encoding for visualization\n",
    "autoencoder.add(Flatten())\n",
    "autoencoder.add(Reshape((4, 4, 8)))\n",
    "\n",
    "# Decoder Layers\n",
    "autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "autoencoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "autoencoder.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "autoencoder.add(UpSampling2D((2, 2)))\n",
    "autoencoder.add(Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\n",
    "\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the encoder layer\n",
    "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('flatten_1').output)\n",
    "encoder.summary()\n",
    "\n",
    "\n",
    "\n",
    "#training the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder_train = autoencoder.fit(X_train, X_train,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                validation_data=(X_test, X_test))\n",
    "\n",
    "#plotting Training loss and Validation loss\n",
    "loss = autoencoder_train.history['loss']\n",
    "val_loss = autoencoder_train.history['val_loss']\n",
    "epochs = range(50)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss',color = 'red')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Means clustering using autoencoder\n",
    "#getting the encoded verson of train data\n",
    "encoded_train = encoder.predict(X_train)\n",
    "\n",
    "# Cluster the training set\n",
    "kmeans = KMeans(n_clusters=10).fit(encoded_train)\n",
    "\n",
    "#getting the encoded verson of test data\n",
    "encoded_imgs = encoder.predict(X_test)\n",
    "clustered_set = kmeans.fit_predict(encoded_imgs)\n",
    "# Centroid values\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Observe and compare clustering result with actual label using confusion matrix\n",
    "y_test = copy.deepcopy(Y_test)\n",
    "cm = confusion_matrix(Y_test, clustered_set)\n",
    "\n",
    "#visualize data\n",
    "plt.figure(figsize=(5, 5))\n",
    "ax = sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.title(\"Confusion matrix for K-means model\", fontsize=25)\n",
    "plt.ylabel('True label', fontsize=20)\n",
    "plt.xlabel('Clustering label', fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "Y_pred = copy.deepcopy(clustered_set)\n",
    "test_accuracy = normalized_mutual_info_score(y_test,Y_pred) \n",
    "print('TESTING ACCURACY: '+str(test_accuracy))\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"----------------------------------------------------\")\n",
    "print(classification_report(Y_test,Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian Mixture Model using Autoencoder\n",
    "#getting the encoded verson of train data\n",
    "encoded_imgs_train = encoder.predict(X_train)\n",
    "gmm = GaussianMixture(n_components=10).fit(encoded_imgs_train)\n",
    "\n",
    "#getting the encoded verson of test data\n",
    "encoded_imgs_test = encoder.predict(X_test)\n",
    "#gmm.fit(encoded_imgs_test)\n",
    "y_pred_gmm = gmm.fit_predict(encoded_imgs_test)\n",
    "proba_lists = gmm.predict_proba(encoded_imgs_test)\n",
    "print(y_pred_gmm.shape)\n",
    "y_test = copy.deepcopy(Y_test)\n",
    "cm = confusion_matrix(Y_test, y_pred_gmm)\n",
    "\n",
    "#visualize the data\n",
    "plt.figure(figsize=(5, 5))\n",
    "ax = sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.title(\"Confusion matrix for GMM model\", fontsize=25)\n",
    "plt.ylabel('True label', fontsize=20)\n",
    "plt.xlabel('Clustering label', fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "Y_pred = copy.deepcopy(y_pred_gmm)\n",
    "test_accuracy = normalized_mutual_info_score(y_test,y_pred_gmm)\n",
    "print('TESTING ACCURACY: '+str(test_accuracy))        \n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"----------------------------------------------------\")\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
